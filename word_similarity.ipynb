{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPF1/wr1gt3QIC3+3CeMbvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjana-psvel/Precog_Task/blob/main/word_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "!pip install nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eFRW5xkRXqv",
        "outputId": "9f82181c-b72e-48de-abf6-9ee07bb13946"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"/content/brown.csv\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL7rKN4zs2z7",
        "outputId": "8e33c9c4-3fe1-4c85-ce68-79d83a9fe403"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      filename  para_id  sent_id  \\\n",
            "0         cd05        0        0   \n",
            "1         cd05        0        1   \n",
            "2         cd05        0        2   \n",
            "3         cd05        0        3   \n",
            "4         cd05        0        4   \n",
            "...        ...      ...      ...   \n",
            "57335     cj14        6        3   \n",
            "57336     cj14        6        4   \n",
            "57337     cj14        6        5   \n",
            "57338     cj14        6        6   \n",
            "57339     cj14        6        7   \n",
            "\n",
            "                                                raw_text  \\\n",
            "0      Furthermore/rb ,/, as/cs an/at encouragement/n...   \n",
            "1      The/at Unitarian/jj clergy/nns were/bed an/at ...   \n",
            "2      Ezra/np Stiles/np Gannett/np ,/, an/at honorab...   \n",
            "3      Even/rb so/rb ,/, Gannett/np judiciously/rb ar...   \n",
            "4      We/ppss today/nr are/ber not/* entitled/vbn to...   \n",
            "...                                                  ...   \n",
            "57335  For/in the/at most/ap part/nn ,/, this/dt disc...   \n",
            "57336                                     A/np-hl ./.-hl   \n",
            "57337  Standard/jj-hl preparations/nns-hl and/cc-hl u...   \n",
            "57338  The/at international/jj unit/nn (/( u./nn )/) ...   \n",
            "57339  The/at international/jj unit/nn is/bez equipot...   \n",
            "\n",
            "                                          tokenized_text  \\\n",
            "0      Furthermore , as an encouragement to revisioni...   \n",
            "1      The Unitarian clergy were an exclusive club of...   \n",
            "2      Ezra Stiles Gannett , an honorable representat...   \n",
            "3      Even so , Gannett judiciously argued , the Ass...   \n",
            "4      We today are not entitled to excoriate honest ...   \n",
            "...                                                  ...   \n",
            "57335  For the most part , this discussion will be co...   \n",
            "57336                                                A .   \n",
            "57337  Standard preparations and units of thyroid-sti...   \n",
            "57338  The international unit ( u. ) , adopted to mak...   \n",
            "57339  The international unit is equipotent with the ...   \n",
            "\n",
            "                                           tokenized_pos     label  \n",
            "0      rb , cs at nn in nn nn , pps rb bez jj to vb c...  religion  \n",
            "1      at jj nns bed at jj nn in vbn nns -- cs at nn ...  religion  \n",
            "2      np np np , at jj nn in at nn , vbd ppl rb in a...  religion  \n",
            "3      rb rb , np rb vbd , at nn-tl md rb vb cs np ``...  religion  \n",
            "4      ppss nr ber * vbn to vb jj nns wps vbd np to b...  religion  \n",
            "...                                                  ...       ...  \n",
            "57335  in at ap nn , dt nn md be vbn in nns vbn in at...   learned  \n",
            "57336                                         np-hl .-hl   learned  \n",
            "57337        jj-hl nns-hl cc-hl nns-hl in-hl jj-hl nn-hl   learned  \n",
            "57338  at jj nn ( nn ) , vbn to vb jj at nn in nns in...   learned  \n",
            "57339  at jj nn bez jj in at nn nn vbn in cd , wdt be...   learned  \n",
            "\n",
            "[57340 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = df['tokenized_text'].tolist()\n",
        "len(text) # no. of sentences in the corpus\n"
      ],
      "metadata": {
        "id": "m4E4EyXcWx2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9cbd52b-7589-4f37-99dd-c0c436a1d698"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57340"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_punctuation(sentence):\n",
        "    # Define a regular expression pattern to match punctuation\n",
        "    punctuation_pattern = r'[^\\w\\s]'\n",
        "    # Use re.sub() to replace punctuation with an empty string\n",
        "    cleaned_sentence = re.sub(punctuation_pattern, '', sentence)\n",
        "    return cleaned_sentence\n",
        "\n",
        "text1=[]\n",
        "for i in text:\n",
        "  text1.append(remove_punctuation(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt4LkJtmZwL5",
        "outputId": "c3898302-6bb6-4027-8749-38926eaa9dde"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grant all this  still  when modern Unitarianism and the Harvard Divinity School recall with humorous affection the insults Parker lavished upon them  or else argue that after all Parker received the treatment he invited  they betray an uneasy conscience \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHrzrBI3eQ87"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}